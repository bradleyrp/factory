# BLUE CRAB SOFTWARE STACK 
# Build and organize software for this cluster.
# USAGE: make spack_hpc_run run=specs/spack_hpc_run.yaml deploy=specs/spack_bc_proot.yaml name=bc-prelim live

# SETTINGS: spack source and environments locations 
spot:       ./local/spack       # config.json, spack
spot_envs:  ./local/envs-spack  # config.json, spack_envs

history: |
  Build through stage01 in sequence.
  The stage01 specs can be added one-by-one.
  Build stage02 openmpi with proot on debug because the build nodes lack verbs.
  Continue stage02 build with singularity.

###
### SOFTWARE SPECIFICATION
###

arch: &arch "arch=linux-centos7-haswell"
gcc-back-compiler: &gcc-back-compiler gcc@4.8.5
gcc-back: &gcc-back !strflush ["%", *gcc-back-compiler]
gcc-7-compiler: &gcc-7-compiler gcc@7.4.0
gcc-7: &gcc-7 !strflush ["%", *gcc-7-compiler, " ", *arch]
python3: &python-3 >-
  python@3.7.6 +bz2 +ctypes +dbm +debug 
  +libxml2 +lzma +optimizations +pic +pyexpat +pythoncmd 
  +readline +shared +sqlite3 +ssl +uuid +zlib
r36: &r36 !chain
  - r@3.6.1 +memory_profiling
  - *python-3

wl02: &wl02 !merge_lists
  #! define below because !merge_lists cannot use refs?
  - &r-packages [r-devtools, r-rcpp]
  - &wl01 [gcc, python, r]
  # each target R package must include dependencies in the whitelist
  - &wl-r-devtools [
    r-callr, r-processx, r-ps, r-r6, r-cli, r-assertthat, r-crayon, 
    r-digest, r-git2r, r-httr, r-curl, r-jsonlite, r-mime, r-openssl, 
    r-askpass, r-sys, r-memoise, r-pkgbuild, r-desc, r-rprojroot, 
    r-backports, r-prettyunits, r-magrittr, r-withr, r-pkgload, 
    r-rlang, r-rstudioapi, r-rcmdcheck, r-sessioninfo, r-xopen, 
    r-remotes, r-roxygen2, r-brew, r-commonmark, r-purrr, r-rcpp, 
    r-stringi, r-stringr, r-glue, r-xml2, r-testthat, r-evaluate, 
    r-praise, r-usethis, r-clipr, r-clisymbols, r-fs, r-gh, r-ini, r-whisker, r-yaml]
  # singleton non-MPI packages
  - &base-singletons [
      cmake, fontconfig, freetype] 
  # python-dependent codes
  - &python-deps [cairo]
  # MPI-compiled codes
  - [gromacs, lammps]
  # incidental to MPI-compiled codes
  - [netcdf-c, hdf5]
  # tensorflow
  - [py-tensorflow@2.1.0 ^cuda@10.1.243]
  #! troubleshooting pkg_resources.DistributionNotFound ...!!!
  - [python, cuda, cudnn, py-absl-py, py-setuptools, py-six, py-astor, 
    py-gast, py-google-pasta, py-grpcio, py-cython, py-keras-applications, 
    py-keras-preprocessing, py-numpy, py-opt-einsum, py-protobuf, py-scipy, 
    py-pybind11, py-termcolor, py-wheel, py-wrapt, py-pip]
  #! previous whitelist for py-tensorflow
  - [py-absl-py, py-setuptools, py-six, py-astor, py-gast,
    py-google-pasta, py-grpcio, py-cython, py-keras-applications,
    py-keras-preprocessing, py-numpy, py-opt-einsum, py-protobuf,
    py-scipy, py-pybind11, py-termcolor, py-wheel, py-wrapt]
  #! attempting to fix tensorflow ...!!!
  - [intel-mkl, libxml]

openmpi-3-1: &openmpi-3-1 >-
  openmpi@3.1.5 %gcc@7.4.0 arch=linux-centos7-haswell
  +cuda +cxx_exceptions fabrics=verbs 
  +legacylaunchers +pmi +vt schedulers=slurm 
  ^slurm@17.11.12 

fftw38: &fftw38 >-
  fftw@3.3.8 +mpi +openmp ~pfft_patches precision=double,float 

lammps: &lammps-v01 >-
  lammps@20190807 +cuda cuda_arch=35
  +asphere +body +class2 +colloid +compress +coreshell
  +dipole +exceptions +ffmpeg +granular +jpeg +kokkos +kspace ~latte +lib +manybody
  +mc +meam +misc +molecule +mpi +mpiio +openmp +peri +png +poems +python +qeq
  +reax +replica +rigid +shock +snap +srd +user-atc +user-h5md +user-lb
  +user-misc +user-netcdf +user-omp +user-reaxc +voronoi
  +user-diffraction 

netcdf-c: &netcdf-c-v01 >-
  netcdf-c@4.7.3 %gcc@7.4.0 ~dap ~hdf4 maxdims=1024 maxvars=8192 
  +mpi ~parallel-netcdf +pic +shared

hdf5: &hdf5-v01 >-
  hdf5@1.10.6 ~cxx ~debug ~fortran +hl +mpi +pic +shared +szip ~threadsafe

cudnn-v01: &cudnn-v01 !str [cudnn@7.6.5.32-10.2-linux-x64, *gcc-7]
cudnn-v03: &cudnn-v03 !str [cudnn@7.6.4.38-10.1-linux-x64, *gcc-7]
cuda-10-2: &cuda-10-2 !str [cuda@10.2.89, *gcc-7]
cuda-10-1: &cuda-10-1 !str [cuda@10.1.243, *gcc-7]
cuda-10-0: &cuda-10-0 !str [cuda@10.0.130, *gcc-7]
mkl-v01: &mkl-v01 !str [intel-mlk@2020.0.166 +shared threads=tbb, *gcc-7]
scipy-v01: &scipy-v01 !str [py-scipy ^intel-mkl, *gcc-7]
tf-est-v02: &tf-est-v02 !str [py-tensorflow-estimator@2.0.0, *gcc-7]

tf-v01: &tf-v01 !chain
  - !str [py-tensorflow@2.1.0 +cuda cuda_arch=35 +numa ~mpi +mkl ~tensorrt ~verbs, *gcc-7]
  - *cuda-10-2
  - *cudnn-v01
  - *scipy-v01
  - *python-3

tf-v02: &tf-v02 !chain
  - !str [py-tensorflow@2.0.0 +cuda cuda_arch=35 +numa ~mpi +mkl ~tensorrt ~verbs, *gcc-7]
  - *cuda-10-2
  - *cudnn-v01
  - *python-3

tf-v03: &tf-v03 !chain
  - !str [py-tensorflow@2.1.0 +cuda cuda_arch=35 +numa ~mpi +mkl ~tensorrt ~verbs, *gcc-7]
  - *cuda-10-1
  - *cudnn-v03
  - *python-3

tf-v04: &tf-v04 !chain
  - !str [py-tensorflow@2.1.0 +cuda cuda_arch=35 +numa ~mpi ~mkl ~tensorrt ~verbs, *gcc-7]
  - *cuda-10-2
  - *cudnn-v01
  - *scipy-v01
  - *python-3


###
### CONFIGURATION
###

# spack environments template (spack.yaml)
template_basic: 
  concretization: separately
  mirrors: {}
  repos: []
  upstreams: {}
  modules:
    enable: []
  definitions: []
  packages: {}
  config: 
    checksum: false
  specs: []
  view: false

# BUILD CONFIGURATION
# matched to the deploy file
bc-config: 
  config: &bc-config
    install_tree: /software/apps/spack/a02
    module_roots: 
      lmod: &module-spot /software/apps/spack/m02
    build_stage:
      - "$TMPDIR/$USER/spack-stage"
    misc_cache: /software/apps/spack/a02/cache_misc
  packages: &packages
    slurm:
      paths:
        slurm@17.11.12: /software/apps/slurm/17.11.12.1.marcc
      buildable: false
      version: []
      providers: {}
      modules: {}
      compiler: []
    openssl:
      paths: {openssl@1.0.2k: /usr}
      buildable: false
    curl:
      # r-curl bug ca 2020.02.08
      version: [7.63.0]

bc-config-modules:
  s01: &mod-stage-01
    enable: 
      - lmod
    lmod:
      all:
        conflict: []
        environment:
          unset: []
        filter:
          environment_blacklist: []
        load: []
      blacklist_implicits: false
      core_compilers:
      - *gcc-back-compiler
      hash_length: 0
      naming_scheme: '{name}/{version}/{compiler.name}/{compiler.version}'
      hierarchy:
      - compiler
      verbose: false

bc-config-modules:
  s01: &mod-stage-02
    enable: 
      - lmod
    lmod: &mod-stage-02-lmod
      all:
        conflict: []
        environment:
          unset: []
        filter:
          environment_blacklist: []
        load: []
      blacklist_implicits: false
      core_compilers:
      - *gcc-back-compiler
      blacklist: 
      - *gcc-back
      hash_length: 0
      hierarchy:
      - compiler
      - mpi
      verbose: false
      openmpi:
        environment:
          set:
            OMPI_MCA_mpi_warn_on_fork: '0'
          unset: []
        filter:
          environment_blacklist: []
        load: []
        conflict: []

mods_config:
  notes: |
    To add a module with python or R dependencies:
      1. Get the full text of the concretize output.
      2. Extract all of the py-name or r-name packages.
      3. Add these to the whitelist above.
      4. Add `autoload: all` for the target under the whitelist below.
    Dev note: it would be nice if this was more seamless.
  mods: &mc01
    config: *bc-config
    packages: *packages
    modules: *mod-stage-01
  mods: &mc02
    config: *bc-config
    packages: *packages
    modules: 
      enable: [lmod]
      lmod: 
        << : *mod-stage-02-lmod
        whitelist: *wl02
        py-tensorflow: 
          autoload: all
          suffixes:
            "^cuda@10.2.89": "cuda-10.2"
        py-scipy: {autoload: all}
        py-numpy: {autoload: all}

###
### ENVIRONMENTS
###

bc-prelim: 
  notes: Initial test before running a compiler build.
  envs:
    - find_compilers: null
    - check_compiler: *gcc-back-compiler
    - bootstrap: null
    - name: env-prelim
      via: template_basic
      mods: *mc01
      specs:
        - !str [zlib, *gcc-back, *arch]
        - !str [cmake, *gcc-back, *arch]

bc-gcc-7-compiler:
  notes: Compile gcc 7 for Blue Crab.
  envs:
    - find_compilers: null
    - check_compiler: *gcc-back-compiler
    - bootstrap: null
    - name: &env-gcc-7-compiler env-gcc-7-compiler
      via: template_basic
      mods: *mc01
      specs:
        - !str &gcc-7-out [*gcc-7-compiler, *gcc-back, *arch]
    - find: *gcc-7-compiler 
      name: *env-gcc-7-compiler

bc-stage01:
  notes: 
    Blue Crab base apps built on gcc7.
    This list was build sequentially during testing.
    See Ryan's notes up to 2020.02.08 for details.
    Note a failed attempt to use spack to supply deps for pdftools namely poppler.
    This failure was due to differences between spack poppler and target poppler-cpp.
  envs:
    - check_compiler: *gcc-7-compiler
    - name: &env-stage01 env-stage01
      via: template_basic
      mods: *mc02
      specs: &stage01-specs !merge_lists
        - [*gcc-7-out]
        # base python
        - [!str [*python-3, *gcc-7]]
        - [!strflush [py-pip, " ^", *python-3, *gcc-7]]
        # base R 
        - [!str [*r36, *gcc-7]]
        # large set of R packages
        - !loopcat
          base: !strflush [" ^", *r36, *gcc-7]
          loop: *r-packages
        # singletons
        - !loopcat
          base: *gcc-7
          loop: *base-singletons
        # tensorflow
        - - !chain [*scipy-v01, *python-3]
          - *tf-v01
        # extra standalone cuda
        - [*cuda-10-1, *cuda-10-0]
        # more tensorflow
        #! - - *tf-v03
        - [!strflush ['gdb+python', " ^", *python-3, *gcc-7]]

bc-stage02:
  notes: |
    Build OpenMPI and MPI-dependent applications.
    Note that we removed lmod refresh after making the production recipe.
    Build strategy: build openmpi and dependencies with proot on debug
    You must have libibverbs and MPI must work. Singularity is not enough.
    There is a curl fork bomb when using proot so use mirror.
    Use spack mirror create openblas to fetch things and then build live in proot.
    Currently we attach CUDA to MPI to make sure we accomodate cuda-aware MPI apps.
    Lammps below requires DPYTHON_EXECUTABLE when building in proot.
    Current MPI build is against spack at [bluecrab e047d7e]
  envs:
    - check_compiler: *gcc-7-compiler
    - name: &env-stage02 env-stage02
      via: template_basic
      mods: *mc02
      specs: &stage02-specs !merge_lists
        - *stage01-specs
        # openmpi builds here with cuda which can change for downstream
        # WARNING: build openmpi in proot
        - [!chain [*openmpi-3-1, &cuda9 "cuda@9.2.88"]]
        - !loopcat
          # openmpi carries cuda so we omit it from the loop
          base: !strflush [" ^", *openmpi-3-1, "^ ", *cuda9]
          loop: 
            - !str [*fftw38, *gcc-7]
            - !chain
              - !str ["gromacs@2019.2 +cuda simd=AVX2_256", *gcc-7]
              - *fftw38
            - *hdf5-v01
            - !chain
              - *netcdf-c-v01
              - *hdf5-v01
            - !chain
              # note that we had to patch spack to set the right python
              # when building in proot via: DPYTHON_EXECUTABLE
              - !str [*lammps-v01, *gcc-7]
              - *python-3
              - *hdf5-v01
              - *netcdf-c-v01
              - *fftw38

bc-singleton:
  notes: Singleton stage for quick building and less concretization.
  envs:
    - check_compiler: *gcc-7-compiler
    - name: &env-singleton env-singleton
      via: template_basic
      mods: *mc02
      specs: 
      specs: !merge_lists
        - [*gcc-7-out]
        # base python
        - [!str [*python-3, *gcc-7]]
        - [!strflush [py-pip, " ^", *python-3, *gcc-7]]
        # tensorflow
        - - *tf-v04
    # add this for testing? ...!!!
    - lmod_refresh: null
      name: *env-singleton

###
### EXTRA MODULEFILES
### 

# anaconda modulefile
anaconda-modulefile: &anaconda-modulefile |
  local name = myModuleName()
  local version = myModuleVersion()
  local root = pathJoin(marccRoot(), name, version)
  help([[ 

  Anaconda environments.

  This module provides the Anaconda package manager which allows
  users to install and user their own virtual environments from 
  the "conda" package distribution repositories.

  To prepare a custom environment:

  module load anaconda
  conda env create -p ./path/to/env
  conda activate ./path/to/env

  You only create the environment once, but you must activate it whenever
  you want to use it. You can also deactivate it ("conda deactiate").

  Note that you will use the absolute path to access this environment later.
  Please put anaconda environments in ~/ or ~/data (because the Lustre 
  filesystem on  ~/scratch and ~/work is not optimized for executables).

  More documentation is here: https://docs.conda.io/en/latest/

  MARCC provides custom environments to save you time (and disk space).
  See the available environments

  See available prepared environments with "conda env list".
  Load these environments with "conda activate <name>". 

  ]])
  whatis("Sets up environment for "..name.." version "..version)
  local conda_exe = os.getenv("CONDA_EXE")
  local myShell = myShellName()
  if (conda_exe == nil or conda_exe == "") or mode()=="load" then
    if (myShell == "bash") then
        cmd = "source " .. pathJoin(root,"/etc/profile.d/conda.sh")
    else
        cmd = "source " .. pathJoin(root,"/etc/profile.d/conda.csh")
    end
    execute{cmd=cmd, modeA = {"load"}}
  elseif mode()=="unload" then
    if (myShell == "bash") then
      cmd = "conda deactivate || : ; " ..
        "unset ANACONDA3ROOT; unset PYTHONROOT; unset CONDA_EXE; " ..
        "unset CONDA_PYTHON_EXE; unset _CE_CONDA; unset _CE_M; " ..
        "unset __add_sys_prefix_to_path; unset __conda_activate; " ..
        "unset __conda_reactivate; unset __conda_hashr; unset CONDA_SHLVL; " ..
        "unset conda"
    else
      cmd = "conda deactivate; " ..
        "unsetenv CONDA_EXE; unsetenv _CONDA_ROOT; unsetenv _CONDA_EXE; " ..
        "unsetenv CONDA_PYTHON_EXE; unset CONDA_SHLVL; unalias conda"
    end
    execute{cmd=cmd, modeA = {"unload"}}
    -- you must remove conda from the path after deactivating
    remove_path("PATH",pathJoin(root,"condabin"))
  end

# marcc module
marcc-modulefile: &marcc-modulefile |
  append_path("PATH","/software/apps/marcc/bin")
  append_path("PATH","/software/apps/slurm/current/bin")
  append_path("PATH","/software/apps/slurm/current/sbin")
  append_path("MANPATH","/software/apps/slurm/current/share/man")
  append_path("LD_LIBRARY_PATH","/software/apps/slurm/current/lib")
  append_path("LD_LIBRARY_PATH","/software/apps/slurm/current/lib/slurm")
  append_path("LIBRARY_PATH","/software/apps/slurm/current/lib")
  append_path("LIBRARY_PATH","/software/apps/slurm/current/lib/slurm")

# extensions module for the centos7 repo
extensions-modulefile: &extensions-modulefile !strflush
  - '-- extension modulefile for software that requires /software/centos7'
  - "\n"
  - '-- append paths so spack can do the heavy lifting'
  - "\n"
  - 'append_path("LD_LIBRARY_PATH","/software/centos7/lib64:'
  - '/software/centos7/lib:'
  - '/software/centos7/usr/lib64:/software/centos7/usr/lib")'
  - "\n"
  - 'append_path("LIBRARY_PATH","/software/centos7/lib64:'
  - '/software/centos7/lib:/software/centos7/usr/lib64:'
  - '/software/centos7/usr/lib")'

# matlab modulefile from the original software tree
matlab-modulefile: &matlab-modulefile |
  whatis([[ Matlab: adds MATLAB to your environment variables ]])
  local name  = myModuleName() -- software name
  local version = myModuleVersion() -- should be of form MAJ.MIN.PATCH
  local root = pathJoin(marccRoot(), name, version, "bin")
  prepend_path("PATH", pathJoin(root, " "))
  setenv("LM_LICENSE_FILE","27000@172.16.0.10")
  -- fonts and X11 XKB are here
  setenv("FONTCONFIG_PATH","/software/centos7/etc/fonts/")
  setenv("XKB_CONFIG_ROOT","/software/centos7/usr/share/X11/xkb/")
  local function isempty(s)
    return s == nil or s == ''
  end
  -- no proot if using non-interactive job
  if not isempty(os.getenv("SLURM_PTY_WIN_ROW")) or
    isempty(os.getenv("SLURM_JOBID")) then
    local bashStr = "/software/apps/proot/5.1.0/bin/proot -b " ..
      "/software/centos7/usr/:/usr/ -b $HOME/.matlab/:/tmp/ " ..
      "/software/apps/matlab/R2019a/bin/matlab -softwareopengl \"$@\"'
    local cshStr = "/software/apps/proot/5.1.0/bin/proot -b " ..
      "/software/centos7/usr/:/usr/ -b $HOME/.matlab/:/tmp/ " .. "
      "/software/apps/matlab/R2019a/bin/matlab -softwareopengl $* "
    set_shell_function("matlab", bashStr, cshStr)
  end

###
### PRODUCTION DEPLOYMENT
### 

production:
  notes: |
    Complete spack build for production.
    Remember to rsync this to production.
    This recipe is best for finalizing modules.
    We recommend adding software in the stages above.
  envs:
    - check_compiler: *gcc-7-compiler
    - name: &env-production env-production
      via: template_basic
      mods: *mc02
      specs: *stage02-specs
    - lmod_refresh: null
      name: *env-production
    # we keep the nested openmpi with hashes for clarity
    # otherwise use: lmod_hide_nested: *module-spot
    # removing hashes failed via: lmod_remove_nested_hashes
    - lmod_hooks:
      # use of the original module facilitates loading via `ml -stack`
      - moduleroot: *module-spot
        modulefile: linux-centos7-x86_64/Core/original.lua
        contents: !strflush
          - 'execute{cmd="echo [STATUS] Loading the original modules. '
          - 'If your default modules includes stack you must clear your cache. '
          - '&& export MODULEPATH='
          - '/software/lmod/modulefiles/compiler_and_base:'
          - '/software/lmod/modulefiles/apps && '
          # return to system defaults. see note below on stack modulefile
          - 'export LMOD_SYSTEM_DEFAULT_MODULES=MARCC/summer-2018 && '
          - 'ml restore",modeA={"load"}}'
      - mkdir: !strflush [*module-spot, '/linux-centos7-x86_64/Core/stack']
      - moduleroot: *module-spot
        modulefile: linux-centos7-x86_64/Core/stack/0.4.lua
        contents: !strflush 
          - 'help([[You are currently using the stack module. '
          - 'This module provides a new set of software managed by Spack. '
          - 'To return to the original modules use ml original.]])'
          - "\n"
          - 'execute{cmd="echo [STATUS] Using the stack module. '
          - 'To use original modules run ml original.",modeA={"load"}}'
          - "\n"
          - 'execute{cmd="echo [STATUS] Using the stack module. '
          - 'To use original modules run ml original.",modeA={"unload"}}'
      # the following modulefile connects to the original modules
      # note that this exists outside the test environment
      - mkdir: /software/lmod/modulefiles/apps/stack
      - moduleroot: /software/lmod/modulefiles/apps/stack
        modulefile: 0.4.lua
        contents: !strflush
          - 'help([[The "stack" module loads the new MARCC software modules. '
          - 'These modules are generated by Spack.]])'
          - "\n"
          - 'execute{cmd="echo [STATUS] Loading the stack module. '
          - 'To use original modules run ml original. '
          - '&& export MODULEPATH='
          - '/software/apps/spack/m02/linux-centos7-x86_64/Core && '
          # setting stack as default prevents conflicts on subshell caused
          #   by the /etc/profile.d/z00_lmod.sh on blue crab however users
          #   will still have to reload some of their modules
          #! dev note: should you have to reload on interact? should you inherit?
          - 'export LMOD_SYSTEM_DEFAULT_MODULES=stack/0.4 && '
          - 'ml purge && ml stack/0.4 && ml gcc/7.4.0 && ml openmpi",modeA={"load"}}'
          - "\n"
          - 'execute{cmd="echo [STATUS] Using the stack module. '
          - 'To use original modules run ml original.",modeA={"unload"}}'
      - mkdir: !strflush [*module-spot, '/linux-centos7-x86_64/Core/marcc']
      - moduleroot: !strflush [*module-spot, '/linux-centos7-x86_64/Core/marcc']
        modulefile: 2020.02.lua
        # append paths to avoid slurm interference
        contents: *marcc-modulefile
    - lmod_defaults:
      - !strflush [*module-spot,'/linux-centos7-x86_64/gcc/7.4.0/openmpi/3.1.5.lua']
      - !strflush [*module-spot,'/linux-centos7-x86_64/Core/gcc/7.4.0.lua']
    # external modules from the original module tree
    - lmod_hooks:
      - mkdir: !strflush [*module-spot, '/linux-centos7-x86_64/Core/anaconda']
      - moduleroot: !strflush [*module-spot, '/linux-centos7-x86_64/Core/anaconda']
        modulefile: 2019.03.lua
        contents: *anaconda-modulefile
      - mkdir: !strflush [*module-spot, '/linux-centos7-x86_64/Core/extensions']
      - moduleroot: !strflush [*module-spot, '/linux-centos7-x86_64/Core/extensions']
        modulefile: 2020.02.lua
        contents: *extensions-modulefile
      - mkdir: !strflush [*module-spot, '/linux-centos7-x86_64/Core/matlab']
      - moduleroot: !strflush [*module-spot, '/linux-centos7-x86_64/Core/matlab']
        modulefile: R2019a.lua
        contents: *matlab-modulefile
